{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Dependency","metadata":{}},{"cell_type":"code","source":"!pip install beautifulsoup4\n!pip install pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T07:49:17.235042Z","iopub.execute_input":"2025-03-15T07:49:17.235393Z","iopub.status.idle":"2025-03-15T07:49:22.714162Z","shell.execute_reply.started":"2025-03-15T07:49:17.235366Z","shell.execute_reply":"2025-03-15T07:49:22.712804Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport csv\nimport re\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T07:49:28.096163Z","iopub.execute_input":"2025-03-15T07:49:28.096584Z","iopub.status.idle":"2025-03-15T07:49:28.436713Z","shell.execute_reply.started":"2025-03-15T07:49:28.096547Z","shell.execute_reply":"2025-03-15T07:49:28.435628Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Extract Data from HTML to CSV","metadata":{}},{"cell_type":"code","source":"# Load the HTML file\nwith open(\"/kaggle/input/dataset-name/My Activity.html\", \"r\", encoding=\"utf-8\") as file:\n    soup = BeautifulSoup(file, \"html.parser\")\n\n# Find all divs with class \"content-cell\"\ncontent_cells = soup.find_all('div', class_='content-cell')\n\n# Extract and store transactions\ndata_rows = []\nfor cell in content_cells:\n    # Extract all text properly\n    text_lines = [text.strip() for text in cell.stripped_strings]\n\n    # Check if the first line contains a valid transaction type\n    if len(text_lines) >= 2 and any(keyword in text_lines[0] for keyword in [\"Paid\", \"Sent\", \"Received\"]):\n        transaction_text = text_lines[0]  # First line is the transaction detail\n        date_text = \" \".join(text_lines[1:])  # Join all remaining lines for date\n        data_rows.append([transaction_text, date_text])\n\n# Write to CSV\ncsv_file = \"transactions.csv\"\nwith open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"Transaction\", \"Date\"])  # Header row\n    writer.writerows(data_rows)\n\nprint(f\"CSV file '{csv_file}' created with {len(data_rows)} transactions!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T07:49:37.009049Z","iopub.execute_input":"2025-03-15T07:49:37.009732Z","iopub.status.idle":"2025-03-15T07:49:40.004880Z","shell.execute_reply.started":"2025-03-15T07:49:37.009697Z","shell.execute_reply":"2025-03-15T07:49:40.003629Z"}},"outputs":[{"name":"stdout","text":"CSV file 'transactions.csv' created with 1702 transactions!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Transform CSV","metadata":{}},{"cell_type":"code","source":"# Input and output file names\ninput_csv = \"transactions.csv\"\noutput_csv = \"cleaned_transactions.csv\"\nskipped_csv = \"skipped_transactions.csv\"  # Debug file for skipped transactions\n\n# Regex patterns:\npattern_paid = re.compile(r\"Paid\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\\s+to\\s+(.+?)(?:\\s+using|$)\")\npattern_paid_no_to = re.compile(r\"Paid\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\\s+using\")\npattern_paid_amount_only = re.compile(r\"Paid\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)$\")\n\npattern_sent = re.compile(r\"Sent\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\\s+to\\s+(.+?)(?:\\s+using|$)\")\npattern_sent_no_to = re.compile(r\"Sent\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\\s+using\")  # Handles missing recipient\npattern_sent_amount_only = re.compile(r\"Sent\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)$\")  # Sent â‚¹100.00\n\npattern_received = re.compile(r\"Received\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\\s+from\\s+(.+?)(?:\\s+using|$)\")\npattern_received_no_from = re.compile(r\"Received\\s+[^\\d]*([\\d,]+(?:\\.\\d+)?)\")\n\n# Read and process the CSV\ndata_rows = []\nskipped_rows = []\nwith open(input_csv, \"r\", encoding=\"utf-8\") as f:\n    reader = csv.reader(f)\n    header = next(reader)  # Skip the header row\n\n    for row in reader:\n        if len(row) < 2:\n            skipped_rows.append(row)  # If row is incomplete, log it\n            continue\n\n        transaction_text, date_text = row  # Extract columns\n\n        # Match different transaction types\n        match_paid = pattern_paid.search(transaction_text)\n        match_paid_no_to = pattern_paid_no_to.search(transaction_text)\n        match_paid_amount_only = pattern_paid_amount_only.search(transaction_text)\n        match_sent = pattern_sent.search(transaction_text)\n        match_sent_no_to = pattern_sent_no_to.search(transaction_text)\n        match_sent_amount_only = pattern_sent_amount_only.search(transaction_text)\n        match_received = pattern_received.search(transaction_text)\n        match_received_no_from = pattern_received_no_from.search(transaction_text)\n\n        if match_paid:\n            amount = match_paid.group(1).replace(\",\", \"\")\n            recipient = match_paid.group(2).strip()\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_paid_no_to:\n            amount = match_paid_no_to.group(1).replace(\",\", \"\")\n            recipient = \"Unknown\"\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_paid_amount_only:\n            amount = match_paid_amount_only.group(1).replace(\",\", \"\")\n            recipient = \"Unknown\"\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_sent:\n            amount = match_sent.group(1).replace(\",\", \"\")\n            recipient = match_sent.group(2).strip()\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_sent_no_to:\n            amount = match_sent_no_to.group(1).replace(\",\", \"\")\n            recipient = \"Unknown\"\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_sent_amount_only:\n            amount = match_sent_amount_only.group(1).replace(\",\", \"\")\n            recipient = \"Unknown\"\n            transaction_type = \"Debit\"\n            by_whom = \"You\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_received:\n            amount = match_received.group(1).replace(\",\", \"\")\n            recipient = \"You\"\n            transaction_type = \"Credit\"\n            by_whom = match_received.group(2).strip()\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        elif match_received_no_from:\n            amount = match_received_no_from.group(1).replace(\",\", \"\")\n            recipient = \"You\"\n            transaction_type = \"Credit\"\n            by_whom = \"Unknown\"\n            data_rows.append([transaction_type, amount, recipient, by_whom, date_text])\n        else:\n            skipped_rows.append(row)  # Log unmatched transactions\n\n# Write the cleaned data to a new CSV\nwith open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"Transaction Type\", \"Amount\", \"To/From\", \"By Whom\", \"Date\"])  # Updated header\n    writer.writerows(data_rows)\n\n# Write skipped rows for analysis\nif skipped_rows:\n    with open(skipped_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\"Transaction\", \"Date\"])  # Header for skipped rows\n        writer.writerows(skipped_rows)\n\nprint(f\" CSV file '{output_csv}' created successfully with {len(data_rows)} transactions.\")\nprint(f\" Skipped {len(skipped_rows)} transactions. Check '{skipped_csv}' for details.\")\n\n# Print first 5 skipped rows for quick debugging\nif skipped_rows:\n    print(\"\\nðŸ” Sample Skipped Transactions:\")\n    for row in skipped_rows[:5]:\n        print(row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T07:49:48.484185Z","iopub.execute_input":"2025-03-15T07:49:48.484550Z","iopub.status.idle":"2025-03-15T07:49:48.521094Z","shell.execute_reply.started":"2025-03-15T07:49:48.484510Z","shell.execute_reply":"2025-03-15T07:49:48.520166Z"}},"outputs":[{"name":"stdout","text":" CSV file 'cleaned_transactions.csv' created successfully with 1702 transactions.\n Skipped 0 transactions. Check 'skipped_transactions.csv' for details.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Load Data and create Montly / Weekly Sheets","metadata":{}},{"cell_type":"code","source":"# Load the cleaned transactions CSV\ninput_csv = \"cleaned_transactions.csv\"\ndf = pd.read_csv(input_csv)\n\n# Convert 'Date' column to datetime format\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\n# Drop rows where date conversion failed\ndf = df.dropna(subset=[\"Date\"])\n\n# Convert 'Amount' column to numeric\ndf[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\n\n# Create Month and Week columns\ndf[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")  # Extract YYYY-MM format\ndf[\"Week\"] = df[\"Date\"].dt.to_period(\"W\")  # Extract YYYY-WW format\n\n# Separate debits (spending) and credits (received)\ndf_debit = df[df[\"Transaction Type\"] == \"Debit\"]\ndf_credit = df[df[\"Transaction Type\"] == \"Credit\"]\n\n### Calculate Monthly Spending & Received ###\nmonthly_spending = df_debit.groupby(\"Month\", as_index=False)[\"Amount\"].sum().rename(columns={\"Amount\": \"Amount_Spent\"})\nmonthly_received = df_credit.groupby(\"Month\", as_index=False)[\"Amount\"].sum().rename(columns={\"Amount\": \"Amount_Received\"})\n\n# Merge spending and received data for monthly report\nmonthly_summary = pd.merge(monthly_spending, monthly_received, on=\"Month\", how=\"outer\").fillna(0)\n\n# Calculate Net Amount (Received - Spent)\nmonthly_summary[\"Net_Amount\"] = monthly_summary[\"Amount_Received\"] - monthly_summary[\"Amount_Spent\"]\n\n# Add a Net Status column to indicate Positive (Surplus) or Negative (Deficit)\nmonthly_summary[\"Net_Status\"] = monthly_summary[\"Net_Amount\"].apply(lambda x: \"Positive\" if x >= 0 else \"Negative\")\n\nmonthly_summary.to_csv(\"monthly_summary.csv\", index=False)\n\n### Calculate Weekly Spending & Received ###\nweekly_spending = df_debit.groupby(\"Week\", as_index=False)[\"Amount\"].sum().rename(columns={\"Amount\": \"Amount_Spent\"})\nweekly_received = df_credit.groupby(\"Week\", as_index=False)[\"Amount\"].sum().rename(columns={\"Amount\": \"Amount_Received\"})\n\n# Merge spending and received data for weekly report\nweekly_summary = pd.merge(weekly_spending, weekly_received, on=\"Week\", how=\"outer\").fillna(0)\n\n# Calculate Net Amount (Received - Spent)\nweekly_summary[\"Net_Amount\"] = weekly_summary[\"Amount_Received\"] - weekly_summary[\"Amount_Spent\"]\n\n# Add a Net Status column\nweekly_summary[\"Net_Status\"] = weekly_summary[\"Net_Amount\"].apply(lambda x: \"Positive\" if x >= 0 else \"Negative\")\n\nweekly_summary.to_csv(\"weekly_summary.csv\", index=False)\n\nprint(\"'monthly_summary.csv' and 'weekly_summary.csv' created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T07:50:25.952999Z","iopub.execute_input":"2025-03-15T07:50:25.953353Z","iopub.status.idle":"2025-03-15T07:50:26.069445Z","shell.execute_reply.started":"2025-03-15T07:50:25.953317Z","shell.execute_reply":"2025-03-15T07:50:26.068367Z"}},"outputs":[{"name":"stdout","text":"'monthly_summary.csv' and 'weekly_summary.csv' created successfully!\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-4cd6f2f3cea2>:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n  df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\")  # Extract YYYY-MM format\n<ipython-input-6-4cd6f2f3cea2>:16: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n  df[\"Week\"] = df[\"Date\"].dt.to_period(\"W\")  # Extract YYYY-WW format\n","output_type":"stream"}],"execution_count":6}]}